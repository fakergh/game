{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n",
        "#is the GPU available?"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfCS09vMaaAm",
        "outputId": "ddd0ea06-360a-4335-dd08-69b401899f58"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Apr 23 14:53:27 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8              12W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LYeAYC7JbKkU"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPmj7C_vanXh",
        "outputId": "11fa7535-5bc6-4abd-f9f3-601a6c7f8e6a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-6jni952y\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-6jni952y\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 5741c522547756ac4bb7a16df32106a15efb8a57\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc4jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMJsVfGva63U",
        "outputId": "dfe9917a-6c1e-498a-e3c7-7cfe6b7e9cd0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The nvcc4jupyter extension is already loaded. To reload it, use:\n",
            "  %reload_ext nvcc4jupyter\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gq6dPfthbl7l",
        "outputId": "2ae6cef8-4e58-4fa4-8197-6ac1e7c4ed22"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <cuda_runtime.h>\n",
        "#include <iostream>\n",
        "\n",
        "__global__ void matmul(int* A, int* B, int* C, int N) {\n",
        "    int Row = blockIdx.y*blockDim.y+threadIdx.y;\n",
        "    int Col = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "    if (Row < N && Col < N) {\n",
        "        int Pvalue = 0;\n",
        "        for (int k = 0; k < N; k++) {\n",
        "            Pvalue += A[Row*N+k] * B[k*N+Col];\n",
        "        }\n",
        "        C[Row*N+Col] = Pvalue;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int N = 512;\n",
        "    int size = N * N * sizeof(int);\n",
        "    int* A, * B, * C;\n",
        "    int* dev_A, * dev_B, * dev_C;\n",
        "    cudaMallocHost(&A, size);\n",
        "    cudaMallocHost(&B, size);\n",
        "    cudaMallocHost(&C, size);\n",
        "    cudaMalloc(&dev_A, size);\n",
        "    cudaMalloc(&dev_B, size);\n",
        "    cudaMalloc(&dev_C, size);\n",
        "\n",
        "    // Initialize matrices A and B\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        for (int j = 0; j < N; j++) {\n",
        "            A[i*N+j] = i*N+j;\n",
        "            B[i*N+j] = j*N+i;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    cudaMemcpy(dev_A, A, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(dev_B, B, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    dim3 dimBlock(16, 16);\n",
        "    dim3 dimGrid(N/dimBlock.x, N/dimBlock.y);\n",
        "\n",
        "    matmul<<<dimGrid, dimBlock>>>(dev_A, dev_B, dev_C, N);\n",
        "\n",
        "    cudaMemcpy(C, dev_C, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Print the result\n",
        "    for (int i = 0; i < 10; i++) {\n",
        "        for (int j = 0; j < 10; j++) {\n",
        "            std::cout << C[i*N+j] << \" \";\n",
        "        }\n",
        "        std::cout << std::endl;\n",
        "    }\n",
        "\n",
        "    // Free memory\n",
        "    cudaFree(dev_A);\n",
        "    cudaFree(dev_B);\n",
        "    cudaFree(dev_C);\n",
        "    cudaFreeHost(A);\n",
        "    cudaFreeHost(B);\n",
        "    cudaFreeHost(C);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nxMy43ubMLx",
        "outputId": "8f7d80c5-6992-44d0-c0da-48ab47acad70"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44608256 111586048 178563840 245541632 312519424 379497216 446475008 513452800 580430592 647408384 \n",
            "111586048 312781568 513977088 715172608 916368128 1117563648 1318759168 1519954688 1721150208 1922345728 \n",
            "178563840 513977088 849390336 1184803584 1520216832 1855630080 -2103923968 -1768510720 -1433097472 -1097684224 \n",
            "245541632 715172608 1184803584 1654434560 2124065536 -1701270784 -1231639808 -762008832 -292377856 177253120 \n",
            "312519424 916368128 1520216832 2124065536 -1567053056 -963204352 -359355648 244493056 848341760 1452190464 \n",
            "379497216 1117563648 1855630080 -1701270784 -963204352 -225137920 512928512 1250994944 1989061376 -1567839488 \n",
            "446475008 1318759168 -2103923968 -1231639808 -359355648 512928512 1385212672 -2037470464 -1165186304 -292902144 \n",
            "513452800 1519954688 -1768510720 -762008832 244493056 1250994944 -2037470464 -1030968576 -24466688 982035200 \n",
            "580430592 1721150208 -1433097472 -292377856 848341760 1989061376 -1165186304 -24466688 1116252928 -2037994752 \n",
            "647408384 1922345728 -1097684224 177253120 1452190464 -1567839488 -292902144 982035200 -2037994752 -763057408 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "__global__ void addVectors(int* A, int* B, int* C, int n)\n",
        "{\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < n)\n",
        "    {\n",
        "        C[i] = A[i] + B[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    int n = 1000000;\n",
        "    int* A, * B, * C;\n",
        "    int size = n * sizeof(int);\n",
        "\n",
        "    // Allocate memory on the host\n",
        "    cudaMallocHost(&A, size);\n",
        "    cudaMallocHost(&B, size);\n",
        "    cudaMallocHost(&C, size);\n",
        "\n",
        "    // Initialize the vectors\n",
        "    for (int i = 0; i < n; i++)\n",
        "    {\n",
        "        A[i] = i;\n",
        "        B[i] = i * 2;\n",
        "    }\n",
        "    // Allocate memory on the device\n",
        "    int* dev_A, * dev_B, * dev_C;\n",
        "    cudaMalloc(&dev_A, size);\n",
        "    cudaMalloc(&dev_B, size);\n",
        "    cudaMalloc(&dev_C, size);\n",
        "\n",
        "    // Copy data from host to device\n",
        "    cudaMemcpy(dev_A, A, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(dev_B, B, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Launch the kernel\n",
        "    int blockSize = 256;\n",
        "    int numBlocks = (n + blockSize - 1) / blockSize;\n",
        "    addVectors<<<numBlocks, blockSize>>>(dev_A, dev_B, dev_C, n);\n",
        "\n",
        "    // Copy data from device to host\n",
        "    cudaMemcpy(C, dev_C, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Print the results\n",
        "    for (int i = 0; i < 10; i++)\n",
        "    {\n",
        "        cout << C[i] << \" \";\n",
        "    }\n",
        "    cout << endl;\n",
        "\n",
        "    // Free memory\n",
        "    cudaFree(dev_A);\n",
        "    cudaFree(dev_B);\n",
        "    cudaFree(dev_C);\n",
        "    cudaFreeHost(A);\n",
        "    cudaFreeHost(B);\n",
        "    cudaFreeHost(C);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3paIY4CdVNw",
        "outputId": "e6db9274-685c-41e9-b633-2bf3ba70949b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 3 6 9 12 15 18 21 24 27 \n",
            "\n"
          ]
        }
      ]
    }
  ]
}